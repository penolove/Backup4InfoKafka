namespace submit;

use application::DTree_Classifier ;


composite optpdf {

	graph
		stream<rstring lines> HDFS2FileSource_1_out0 = com.ibm.streamsx.hdfs::HDFS2FileSource()
		{
			param
				hdfsUri : "hdfs://info1:9000" ;
				file : "/user/flows5g.txt" ;
			config placement: host(HDFSreader);
				   
		}
		@parallel(width=8)
		stream<application::Feature> createmap0 = Custom(HDFS2FileSource_1_out0)
		{
			logic
				state :
				{
					mutable map<rstring, float64> counter ;
					mutable list<rstring> attr = [ 'packet1', 'packet2', 'packet3', 'packet4',
						'packet5', 'No_segA', 'No_segB', 'No_segFr', 'totalsizA', 'totalsizB',
						'totalsizFr', 'dport', 'sport' ] ;
					mutable list<rstring> temp ;
				}

				onTuple HDFS2FileSource_1_out0 :
				{
					temp = tokenize(lines, ",", true) ;
					if(size(temp) == 13)
					{
						for(int32 k in range(0, 13))
						{
							counter [ attr [ k ] ] =(float64) temp [ k ] ;
						}

						submit({ flowID = { srcAddr = "123", srcPort =(uint16) 456, dstAddr =
							"123", dstPort =(uint16) 456 }, features = counter }, createmap0) ;
					}

				}
			config placement: host(createmap);
			}
		
		@parallel(width=2)
		(stream<application::FlowID flowID, rstring label > LabelStream1; stream<rstring topic,rstring message> OutputStream) as DTree1 =DTree_Classifier(createmap0)
		{
			param
				filename : "/user/124.txt" ;
			config
				placement : host(HDFSreader);

		}
	config hostPool: 
		HDFSreader = createPool({tags=["HDFSreader"], size=1}, Sys.Exclusive),
		createmap = createPool({tags=["createmap"], size=2}, Sys.Exclusive);
  		//decision = createPool({tags=["decision"], size=1}, Sys.Exclusive);

}


